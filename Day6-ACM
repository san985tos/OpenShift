
### ACM 

# Revire ACM Operator Installation

# ACM cloud credentials (Azure)


# ACM cloud credentials (AWS)
╰─○ Cloud Provider: Choose Amazon Web Services
╰─○ Credential Name: aws
╰─○ Namespace: open-cluster-management
╰─○ Base DNS Domain: This is in the email from the RHPDS system
╰─○ Access Key ID: This is in the email from the RHPDS system
╰─○ Secret Access Key ID: This is in the email from the RHPDS system
╰─○ Red Hat OpenShift pull secret: Get from your Red Hat login
╰─○ SSH private and public keys: Use an existing key pair or generate a new one (see link below)

# Create a new OpenShift cluster in AWS
╰─○ Select Red Hat OpenShift.
╰─○ Select Amazon Web services.
╰─○ Select the Infrastructure provider credential - aws - Click NEXT Add the desired cluster name. Leave the Cluster set empty for now Select a Release Image, chose a 4.8 version
╰─○ Add a label of environment=prod. Click NEXT
╰─○ Change the region to: Select us-west-1 or us-west-2

# Creating a Single Node Cluster 
╰─○ Select Red Hat OpenShift.
╰─○ Select Amazon Web services.
╰─○ Select the Infrastructure provider credential - aws - Click NEXT Add the desired cluster name. Leave the Cluster set empty for now Select a Release Image, chose a OCP 4.8 version
╰─○ Add a label of environment=qa. Click NEXT
╰─○ Change the region to *see table below*

# Creating an Application
╰─○ On the local cluster add a label: environment=dev
╰─○ On the new cluster you provisioned via ACM double check you added the label: environment=prod
╰─○ Within ACM navigate to Manage Application and click Create application. Enter the following information:
╰─○ Next to Create and application click the YAML dial to ON
╰─○ Name: book-import
╰─○ Namespace: book-import
╰─○ Under repository types, select the GIT repository
╰─○ URL: https://github.com/hichammourad/book-import.git
╰─○ Branch: master-no-pre-post Path: book-import

 Edit it and change the label to environment=prod. What happens to the application?






### Serverless Knative

# Install Operator "serverless"

Select the installed operator and review the Condition section

Install KnativeServing

Create the project (if does not exist)
╰─○ oc new-project knative-serving

you must create a KnativeServing object to install Knative Serving using the OpenShift Serverless Operator.
╰─○ Select KnativeServing
╰─○ Select YAML view and modify as:

╰─○ On Console, change to project "knative-serving"
╰─○ Select KnativeServing instance and validate on Conditions (at button) all are in true status

# Deploying your first knative service

Create a project
╰─○ oc new-project serverless-tutorial

Deploy the Serverless Service
╰─○ kn service create greeter \
 --image quay.io/rhdevelopers/knative-tutorial-greeter:quarkus \
 --namespace serverless-tutorial

List and verify the service from kn client
╰─○ kn service list

List service route
╰─○ kn route list

Describe the service
╰─○ kn service describe greeter

Check the deployment 'READY' Column
╰─○ oc get deployment

# Revisions

- A Revision is a point-in-time snapshot of the code and configuration for each modification made to the workload.
- Revisions are immutable objects and can be retained for as long as needed.

Update Kn service
╰─○ kn service update greeter \
 --image quay.io/rhdevelopers/knative-tutorial-greeter:latest \
 --namespace serverless-tutorial

    # Note: Updating the image of the service will create a new revision, or point-in-time snapshot of the workload.

We can see the revision by executing:
╰─○ kn revision list

    # pay attention to TRAFFIC column

To invoke the service we can execute the command:
╰─○ export APP_ROUTE=$(kn route list | awk '{print $2}' | sed -n 2p)
curl --insecure $APP_ROUTE

The greeter service will automatically scale down to zero if it does not get request for approximately 90 seconds.

Delete the Service:
╰─○ kn service delete greeter
╰─○ kn service list

# Traffic Distribution

Objectives:

- Provide a custom name to the deployment
- Configure a service to use a blue-green deployment pattern

Serverless services always route traffic to the latest revision of the deployment.
Serverless generates random revision names for the service that is based on using the Serverless service’s metadata.name as a prefix.

The following service deployment uses the same greeter service as the last section except it is configured with an arbitrary revision name.
╰─○ kn service create greeter \
 --image quay.io/rhdevelopers/knative-tutorial-greeter:quarkus \
 --namespace serverless-tutorial \
 --revision-name greeter-v1

Update the greeter service to add a message prefix environment variable and change the revision name to greeter-v2:
╰─○ kn service update greeter \
 --image quay.io/rhdevelopers/knative-tutorial-greeter:quarkus \
 --namespace serverless-tutorial \
 --revision-name greeter-v2 \
 --env MESSAGE_PREFIX=GreeterV2
╰─○ kn revision list

# Blue-Green Deployment Patterns

- Serverless offers a simple way of switching 100% of the traffic from one Serverless service revision (blue) to another newly rolled out revision (green).
- We can rollback to a previous revision if any new revision (e.g. green) has any unexpected behaviors.

Update the greeter service by executing:
╰─○ kn revision list  
╰─○ kn service update greeter \
 --traffic greeter-v1=100 \
 --tag greeter-v1=current \
 --tag greeter-v2=prev \
 --tag @latest=latest
╰─○ kn revision list

Optional:

╰─○ kn service update greeter \
 --traffic greeter-v2=100
╰─○ kn revision list

- The above service definition creates three sub-routes(named after traffic tags) to the existing greeter route.
  - current: The revision will receive 100% of the traffic distribution
  - prev: The previously active revision, which will now receive no traffic
  - latest: The route pointing to the latest service deployment, here we change the default configuration to receive no traffic.

Using the latest tag allows changing the default behavior of services to route 100% of the traffic to the latest revision.
╰─○ kn route describe greeter

Check that greeter-v1 is receiving 100% of the traffic now to our main route by executing:
╰─○ APP_ROUTE=$(kn route list | awk '{print $2}' | sed -n 2p)
curl --insecure $APP_ROUTE

# Canary Releases

- A Canary release is more effective when looking to reduce the risk of introducing new features.
- Using this type of deployment model allows a more effective feature-feedback loop before rolling out the change to the entire user base.
- Using this deployment approach with Serverless allows splitting the traffic between revisions in increments as small as 1%.

To see this in action, apply the following service update that will split the traffic 80% to 20% between greeter-v1 and greeter-v2 by executing:
╰─○ kn service update greeter \
 --traffic greeter-v1=80 \
 --traffic greeter-v2=20 \
 --traffic @latest=0
╰─○ kn revision list

To observe the new traffic distribution execute the following:
╰─○ APP_ROUTE=$(kn route list | awk '{print $2}' | sed -n 2p)

for run in {1..10}
do
curl --insecure $APP_ROUTE
done

Also notice that two pods are running, representing both greeter-v1 and greeter-v2:
╰─○ oc get pods -n serverless-tutorial

Delete the Service
╰─○ kn service delete greeter

Clenup

╰─○ oc delete project knative-eventing knative-serving knative-serving-ingress serverless-tutorial
╰─○ Uninstall Operator
